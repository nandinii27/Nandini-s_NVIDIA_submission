{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d626e3d0-69c0-44b9-ac2c-92e523ea7dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/jovyan\n",
      "\n",
      "Files here: ['.bashrc', '2026-NVIDIA', '.config', '.jupyter', '.npm', '.profile', '.bash_logout', '.ipython', '.ipynb_checkpoints', '.local', 'labs_hybrid_optimizer', '.vim', '.virtual_documents', '.aws', '.conda', '.qbraid_restore_progress.json', 'labs_pipeline.ipynb', '.qbraid_priority_restored', '.ssh', '.viminfo', '.mcp', '.qbraid', '.qbraid_data_ready', '.cache', '.pod_agent', '.claude', 'labs_results_n20.json', '.hotdog']\n",
      "\n",
      "✓ Project folder found at: /home/jovyan/labs_hybrid_optimizer\n",
      "  Contents: ['utils.py', 'run_labs.py', 'mts_optimizer.py', 'dcqo_sampler.py', 'labs_hybrid_optimizer', 'tda_analysis.py', 'quality_predictor.py', 'diversity_selector.py', 'pipeline.py']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Check current directory\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# List files in current directory\n",
    "print(f\"\\nFiles here: {os.listdir('.')}\")\n",
    "\n",
    "# Check if our project folder exists\n",
    "project_path = os.path.expanduser(\"~/labs_hybrid_optimizer\")\n",
    "if os.path.exists(project_path):\n",
    "    print(f\"\\n✓ Project folder found at: {project_path}\")\n",
    "    print(f\"  Contents: {os.listdir(project_path)}\")\n",
    "else:\n",
    "    print(f\"\\n✗ Project folder not found at: {project_path}\")\n",
    "    \n",
    "    # Search for it\n",
    "    home = os.path.expanduser(\"~\")\n",
    "    print(f\"\\nSearching in home directory ({home})...\")\n",
    "    for item in os.listdir(home):\n",
    "        print(f\"  {item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdf167fe-3455-489e-b174-28866aa2580a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilities loaded successfully!\n",
      "Test sequence energy: 140\n",
      "Test sequence merit factor: 0.229\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Core utilities and setup\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============== UTILS ==============\n",
    "def labs_energy(sequence: np.ndarray) -> int:\n",
    "    \"\"\"Compute LABS energy E(s) = sum_k C_k^2\"\"\"\n",
    "    N = len(sequence)\n",
    "    energy = 0\n",
    "    for k in range(1, N):\n",
    "        C_k = sum(sequence[i] * sequence[i + k] for i in range(N - k))\n",
    "        energy += C_k ** 2\n",
    "    return energy\n",
    "\n",
    "def merit_factor(sequence: np.ndarray) -> float:\n",
    "    \"\"\"Merit factor F = N^2 / (2 * E(s))\"\"\"\n",
    "    N = len(sequence)\n",
    "    E = labs_energy(sequence)\n",
    "    return N ** 2 / (2 * E) if E > 0 else float('inf')\n",
    "\n",
    "def bitstring_to_sequence(bitstring: str) -> np.ndarray:\n",
    "    \"\"\"Convert '0110' to [-1, +1, +1, -1]\"\"\"\n",
    "    return np.array([1 if b == '1' else -1 for b in bitstring])\n",
    "\n",
    "def sequence_to_bitstring(sequence: np.ndarray) -> str:\n",
    "    \"\"\"Convert [-1, +1, +1, -1] to '0110'\"\"\"\n",
    "    return ''.join('1' if s == 1 else '0' for s in sequence)\n",
    "\n",
    "def local_gradient(sequence: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute energy change for each single-bit flip\"\"\"\n",
    "    N = len(sequence)\n",
    "    current_energy = labs_energy(sequence)\n",
    "    gradients = np.zeros(N)\n",
    "    for i in range(N):\n",
    "        flipped = sequence.copy()\n",
    "        flipped[i] *= -1\n",
    "        gradients[i] = labs_energy(flipped) - current_energy\n",
    "    return gradients\n",
    "\n",
    "print(\"Utilities loaded successfully!\")\n",
    "\n",
    "# Quick test\n",
    "test_seq = np.array([1, -1, 1, -1, 1, -1, 1, -1])\n",
    "print(f\"Test sequence energy: {labs_energy(test_seq)}\")\n",
    "print(f\"Test sequence merit factor: {merit_factor(test_seq):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a23a68e0-6a6e-4e86-b848-49d57f655624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCQO Sampler loaded!\n",
      "Circuit: 8 qubits, depth 25\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: DCQO Quantum Sampler (FIXED)\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit_aer import AerSimulator\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class DCQOSampler:\n",
    "    \"\"\"Digitized Counterdiabatic Quantum Optimization for LABS\"\"\"\n",
    "    \n",
    "    def __init__(self, N: int, num_layers: int = 3):\n",
    "        self.N = N\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "    def build_circuit(self, params: Dict[str, float] = None) -> QuantumCircuit:\n",
    "        \"\"\"Build the DCQO circuit for LABS\"\"\"\n",
    "        N = self.N\n",
    "        qr = QuantumRegister(N, 'q')\n",
    "        cr = ClassicalRegister(N, 'c')\n",
    "        qc = QuantumCircuit(qr, cr)\n",
    "        \n",
    "        # Default parameters\n",
    "        if params is None:\n",
    "            params = {}\n",
    "            for layer in range(self.num_layers):\n",
    "                t = (layer + 1) / self.num_layers\n",
    "                params[f'gamma_{layer}'] = 0.4 * t\n",
    "                params[f'alpha_{layer}'] = 0.6 * (1 - t)\n",
    "                params[f'beta_{layer}'] = 0.15 * np.sin(np.pi * t)\n",
    "        \n",
    "        # Initial superposition\n",
    "        for i in range(N):\n",
    "            qc.h(i)\n",
    "        \n",
    "        # DCQO layers\n",
    "        for layer in range(self.num_layers):\n",
    "            t = (layer + 1) / self.num_layers\n",
    "            gamma = params.get(f'gamma_{layer}', 0.4 * t)\n",
    "            alpha = params.get(f'alpha_{layer}', 0.6 * (1 - t))\n",
    "            beta = params.get(f'beta_{layer}', 0.15 * np.sin(np.pi * t))\n",
    "            \n",
    "            # Problem Hamiltonian: ZZ interactions\n",
    "            for i in range(N - 1):\n",
    "                qc.rzz(gamma * 0.5, i, i + 1)\n",
    "            \n",
    "            # Long-range ZZ for autocorrelation\n",
    "            for k in range(2, min(N, 4)):\n",
    "                for i in range(N - k):\n",
    "                    qc.rzz(gamma * 0.25 / k, i, i + k)\n",
    "            \n",
    "            # Counterdiabatic Y rotations\n",
    "            for i in range(N):\n",
    "                qc.ry(alpha, i)\n",
    "            \n",
    "            # Bias field\n",
    "            for i in range(N):\n",
    "                qc.rz(beta * (i - N/2) / N, i)\n",
    "        \n",
    "        qc.measure(qr, cr)\n",
    "        return qc\n",
    "    \n",
    "    def sample(self, num_samples: int = 1000) -> List[Tuple[np.ndarray, int]]:\n",
    "        \"\"\"Generate DCQO samples\"\"\"\n",
    "        qc = self.build_circuit()\n",
    "        \n",
    "        # FIX: Explicitly use MPS method for large circuits\n",
    "        simulator = AerSimulator(method='matrix_product_state')\n",
    "        job = simulator.run(qc, shots=num_samples)\n",
    "        counts = job.result().get_counts()\n",
    "        \n",
    "        # Convert to sequences with energies\n",
    "        samples = []\n",
    "        for bitstring, count in counts.items():\n",
    "            seq = bitstring_to_sequence(bitstring[::-1])\n",
    "            energy = labs_energy(seq)\n",
    "            samples.extend([(seq, energy)] * count)\n",
    "        \n",
    "        samples.sort(key=lambda x: x[1])\n",
    "        return samples\n",
    "\n",
    "print(\"DCQO Sampler loaded!\")\n",
    "\n",
    "# Quick test\n",
    "sampler = DCQOSampler(N=8, num_layers=2)\n",
    "qc = sampler.build_circuit()\n",
    "print(f\"Circuit: {qc.num_qubits} qubits, depth {qc.depth()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0126ce-a668-4119-9465-80c35fcbe593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ripser available for persistent homology\n",
      "TDA Basin Analyzer loaded!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: TDA Basin Analysis\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "# Try to import ripser, fall back to scipy if not available\n",
    "try:\n",
    "    import ripser\n",
    "    RIPSER_AVAILABLE = True\n",
    "    print(\"Ripser available for persistent homology\")\n",
    "except ImportError:\n",
    "    RIPSER_AVAILABLE = False\n",
    "    print(\"Ripser not found, using scipy fallback\")\n",
    "\n",
    "class TDABasinAnalyzer:\n",
    "    \"\"\"TDA for identifying solution basins using H0 persistent homology\"\"\"\n",
    "    \n",
    "    def __init__(self, persistence_threshold: float = 0.1):\n",
    "        self.persistence_threshold = persistence_threshold\n",
    "        self.persistence_diagram = None\n",
    "        self.cluster_labels = None\n",
    "        self.basin_info = None\n",
    "    \n",
    "    def compute_persistence(self, sequences: List[np.ndarray], \n",
    "                           energies: List[int] = None) -> Dict:\n",
    "        \"\"\"Compute H0 persistent homology in Hamming space\"\"\"\n",
    "        n_samples = len(sequences)\n",
    "        \n",
    "        # Compute Hamming distance matrix\n",
    "        dist_matrix = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(i + 1, n_samples):\n",
    "                d = np.sum(sequences[i] != sequences[j])\n",
    "                dist_matrix[i, j] = d\n",
    "                dist_matrix[j, i] = d\n",
    "        \n",
    "        # Energy-weighted distance (optional)\n",
    "        if energies is not None:\n",
    "            energy_arr = np.array(energies)\n",
    "            energy_diff = np.abs(energy_arr[:, None] - energy_arr[None, :])\n",
    "            max_diff = energy_diff.max() if energy_diff.max() > 0 else 1\n",
    "            dist_matrix = dist_matrix + 0.1 * (energy_diff / max_diff) * dist_matrix.max()\n",
    "        \n",
    "        # Compute persistence\n",
    "        if RIPSER_AVAILABLE:\n",
    "            result = ripser.ripser(dist_matrix, maxdim=0, distance_matrix=True)\n",
    "            self.persistence_diagram = result['dgms'][0]\n",
    "        else:\n",
    "            # Fallback: approximate via single-linkage\n",
    "            self.persistence_diagram = self._approximate_persistence(dist_matrix)\n",
    "        \n",
    "        self.basin_info = self._analyze_basins(n_samples)\n",
    "        \n",
    "        return {\n",
    "            'persistence_diagram': self.persistence_diagram,\n",
    "            'basin_info': self.basin_info,\n",
    "            'distance_matrix': dist_matrix\n",
    "        }\n",
    "    \n",
    "    def _approximate_persistence(self, dist_matrix: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Approximate H0 persistence using single-linkage clustering\"\"\"\n",
    "        condensed = squareform(dist_matrix)\n",
    "        Z = linkage(condensed, method='single')\n",
    "        n = dist_matrix.shape[0]\n",
    "        births = np.zeros(n - 1)\n",
    "        deaths = Z[:, 2]\n",
    "        return np.column_stack([births, deaths])\n",
    "    \n",
    "    def _analyze_basins(self, n_samples: int) -> Dict:\n",
    "        \"\"\"Analyze persistence diagram for basin structure\"\"\"\n",
    "        if self.persistence_diagram is None or len(self.persistence_diagram) == 0:\n",
    "            return {'num_basins': 1, 'persistence_values': []}\n",
    "        \n",
    "        births = self.persistence_diagram[:, 0]\n",
    "        deaths = self.persistence_diagram[:, 1]\n",
    "        persistence = deaths - births\n",
    "        \n",
    "        finite_mask = np.isfinite(deaths)\n",
    "        finite_persistence = persistence[finite_mask]\n",
    "        \n",
    "        if len(finite_persistence) == 0:\n",
    "            return {'num_basins': 1, 'persistence_values': []}\n",
    "        \n",
    "        median_pers = np.median(finite_persistence)\n",
    "        q75, q25 = np.percentile(finite_persistence, [75, 25])\n",
    "        threshold = median_pers + self.persistence_threshold * (q75 - q25)\n",
    "        \n",
    "        long_mask = persistence > threshold\n",
    "        \n",
    "        return {\n",
    "            'num_basins': np.sum(long_mask) + 1,\n",
    "            'threshold': threshold,\n",
    "            'persistence_values': persistence,\n",
    "            'median_persistence': median_pers\n",
    "        }\n",
    "    \n",
    "    def assign_clusters(self, sequences: List[np.ndarray], \n",
    "                       dist_matrix: np.ndarray = None,\n",
    "                       n_clusters: int = None) -> np.ndarray:\n",
    "        \"\"\"Assign sequences to clusters\"\"\"\n",
    "        n_samples = len(sequences)\n",
    "        \n",
    "        if dist_matrix is None:\n",
    "            dist_matrix = np.zeros((n_samples, n_samples))\n",
    "            for i in range(n_samples):\n",
    "                for j in range(i + 1, n_samples):\n",
    "                    d = np.sum(sequences[i] != sequences[j])\n",
    "                    dist_matrix[i, j] = d\n",
    "                    dist_matrix[j, i] = d\n",
    "        \n",
    "        if n_clusters is None:\n",
    "            n_clusters = max(2, self.basin_info.get('num_basins', 3) if self.basin_info else 3)\n",
    "        \n",
    "        condensed = squareform(dist_matrix)\n",
    "        Z = linkage(condensed, method='average')\n",
    "        self.cluster_labels = fcluster(Z, n_clusters, criterion='maxclust')\n",
    "        \n",
    "        return self.cluster_labels\n",
    "\n",
    "print(\"TDA Basin Analyzer loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d696c193-abe4-418e-8864-f86cf11e86ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity Selector loaded!\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Diversity-Aware Selection\n",
    "class DiversitySelector:\n",
    "    \"\"\"Diversity-aware seed selection combining TDA clustering with quality ranking\"\"\"\n",
    "    \n",
    "    def __init__(self, tda_weight: float = 0.5, energy_weight: float = 0.5):\n",
    "        self.tda_weight = tda_weight\n",
    "        self.energy_weight = energy_weight\n",
    "    \n",
    "    def _normalize(self, values: List[float]) -> np.ndarray:\n",
    "        \"\"\"Normalize values to [0, 1] range\"\"\"\n",
    "        values = np.array(values, dtype=float)\n",
    "        min_val, max_val = values.min(), values.max()\n",
    "        if max_val - min_val < 1e-10:\n",
    "            return np.zeros_like(values)\n",
    "        return (values - min_val) / (max_val - min_val)\n",
    "    \n",
    "    def select_seeds(self,\n",
    "                     sequences: List[np.ndarray],\n",
    "                     energies: List[int],\n",
    "                     cluster_labels: np.ndarray,\n",
    "                     n_seeds: int = 10,\n",
    "                     diversity_bonus: float = 0.3) -> List[int]:\n",
    "        \"\"\"Select diverse, high-quality seeds for MTS\"\"\"\n",
    "        n_samples = len(sequences)\n",
    "        energy_scores = self._normalize(energies)\n",
    "        \n",
    "        # Greedy selection with diversity bonus\n",
    "        selected = []\n",
    "        selected_clusters = {}\n",
    "        \n",
    "        for _ in range(min(n_seeds, n_samples)):\n",
    "            best_idx = -1\n",
    "            best_score = float('inf')\n",
    "            \n",
    "            for i in range(n_samples):\n",
    "                if i in selected:\n",
    "                    continue\n",
    "                \n",
    "                # Diversity penalty for over-represented clusters\n",
    "                cluster = cluster_labels[i]\n",
    "                cluster_selected = selected_clusters.get(cluster, 0)\n",
    "                diversity_penalty = diversity_bonus * cluster_selected\n",
    "                \n",
    "                adjusted_score = energy_scores[i] + diversity_penalty\n",
    "                \n",
    "                if adjusted_score < best_score:\n",
    "                    best_score = adjusted_score\n",
    "                    best_idx = i\n",
    "            \n",
    "            if best_idx >= 0:\n",
    "                selected.append(best_idx)\n",
    "                cluster = cluster_labels[best_idx]\n",
    "                selected_clusters[cluster] = selected_clusters.get(cluster, 0) + 1\n",
    "        \n",
    "        return selected\n",
    "\n",
    "print(\"Diversity Selector loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04500ac7-7ccb-48f0-a4c3-b4382ed6f8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memetic Tabu Search loaded!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Memetic Tabu Search\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class MemeticTabuSearch:\n",
    "    \"\"\"Memetic Tabu Search optimizer for LABS\"\"\"\n",
    "    \n",
    "    def __init__(self, N: int, tabu_tenure: int = None,\n",
    "                 population_size: int = 10, max_iterations: int = 5000,\n",
    "                 stagnation_limit: int = 100):\n",
    "        self.N = N\n",
    "        self.tabu_tenure = tabu_tenure or N // 2\n",
    "        self.population_size = population_size\n",
    "        self.max_iterations = max_iterations\n",
    "        self.stagnation_limit = stagnation_limit\n",
    "        \n",
    "        self.iteration_count = 0\n",
    "        self.eval_count = 0\n",
    "        self.best_energy = float('inf')\n",
    "        self.best_sequence = None\n",
    "        self.convergence_history = []\n",
    "    \n",
    "    def _labs_energy(self, sequence: np.ndarray) -> int:\n",
    "        \"\"\"Compute LABS energy (with counting)\"\"\"\n",
    "        self.eval_count += 1\n",
    "        N = len(sequence)\n",
    "        energy = 0\n",
    "        for k in range(1, N):\n",
    "            C_k = sum(sequence[i] * sequence[i + k] for i in range(N - k))\n",
    "            energy += C_k ** 2\n",
    "        return energy\n",
    "    \n",
    "    def local_search(self, sequence: np.ndarray, max_steps: int = 100) -> Tuple[np.ndarray, int, int]:\n",
    "        \"\"\"Tabu search local optimization\"\"\"\n",
    "        current = sequence.copy()\n",
    "        current_energy = self._labs_energy(current)\n",
    "        \n",
    "        tabu_list = deque(maxlen=self.tabu_tenure)\n",
    "        best_local = current.copy()\n",
    "        best_local_energy = current_energy\n",
    "        steps_without_improvement = 0\n",
    "        \n",
    "        for step in range(max_steps):\n",
    "            best_move = -1\n",
    "            best_move_energy = float('inf')\n",
    "            \n",
    "            for i in range(self.N):\n",
    "                # Evaluate flip\n",
    "                current[i] *= -1\n",
    "                new_energy = self._labs_energy(current)\n",
    "                current[i] *= -1\n",
    "                \n",
    "                # Check if move is allowed (not tabu or aspiration)\n",
    "                if i not in tabu_list or new_energy < best_local_energy:\n",
    "                    if new_energy < best_move_energy:\n",
    "                        best_move = i\n",
    "                        best_move_energy = new_energy\n",
    "            \n",
    "            if best_move < 0:\n",
    "                break\n",
    "            \n",
    "            # Make the move\n",
    "            current[best_move] *= -1\n",
    "            current_energy = best_move_energy\n",
    "            tabu_list.append(best_move)\n",
    "            \n",
    "            if current_energy < best_local_energy:\n",
    "                best_local = current.copy()\n",
    "                best_local_energy = current_energy\n",
    "                steps_without_improvement = 0\n",
    "            else:\n",
    "                steps_without_improvement += 1\n",
    "            \n",
    "            if steps_without_improvement >= self.stagnation_limit // 2:\n",
    "                break\n",
    "        \n",
    "        return best_local, best_local_energy, step + 1\n",
    "    \n",
    "    def crossover(self, parent1: np.ndarray, parent2: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Two-point crossover\"\"\"\n",
    "        N = len(parent1)\n",
    "        pt1, pt2 = sorted(random.sample(range(N), 2))\n",
    "        child = parent1.copy()\n",
    "        child[pt1:pt2] = parent2[pt1:pt2]\n",
    "        return child\n",
    "    \n",
    "    def mutate(self, sequence: np.ndarray, rate: float = 0.1) -> np.ndarray:\n",
    "        \"\"\"Random bit flip mutation\"\"\"\n",
    "        mutated = sequence.copy()\n",
    "        for i in range(len(mutated)):\n",
    "            if random.random() < rate:\n",
    "                mutated[i] *= -1\n",
    "        return mutated\n",
    "    \n",
    "    def optimize(self, initial_population: List[np.ndarray] = None,\n",
    "                 verbose: bool = True) -> Tuple[np.ndarray, int, Dict]:\n",
    "        \"\"\"Run the full MTS optimization\"\"\"\n",
    "        \n",
    "        # Initialize population\n",
    "        if initial_population is None:\n",
    "            population = [np.random.choice([-1, 1], self.N) \n",
    "                         for _ in range(self.population_size)]\n",
    "        else:\n",
    "            population = [seq.copy() for seq in initial_population[:self.population_size]]\n",
    "            while len(population) < self.population_size:\n",
    "                population.append(np.random.choice([-1, 1], self.N))\n",
    "        \n",
    "        # Evaluate initial population\n",
    "        pop_with_energy = [(seq, self._labs_energy(seq)) for seq in population]\n",
    "        pop_with_energy.sort(key=lambda x: x[1])\n",
    "        \n",
    "        self.best_sequence = pop_with_energy[0][0].copy()\n",
    "        self.best_energy = pop_with_energy[0][1]\n",
    "        \n",
    "        stagnation_counter = 0\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            self.iteration_count = iteration\n",
    "            \n",
    "            # Local search on each individual\n",
    "            improved_pop = []\n",
    "            for seq, energy in pop_with_energy:\n",
    "                improved_seq, improved_energy, _ = self.local_search(seq, max_steps=50)\n",
    "                improved_pop.append((improved_seq, improved_energy))\n",
    "            \n",
    "            # Update best\n",
    "            improved_pop.sort(key=lambda x: x[1])\n",
    "            if improved_pop[0][1] < self.best_energy:\n",
    "                self.best_energy = improved_pop[0][1]\n",
    "                self.best_sequence = improved_pop[0][0].copy()\n",
    "                stagnation_counter = 0\n",
    "                \n",
    "                if verbose:\n",
    "                    merit = self.N ** 2 / (2 * self.best_energy) if self.best_energy > 0 else float('inf')\n",
    "                    print(f\"Iter {iteration}: New best E={self.best_energy}, F={merit:.3f}\")\n",
    "            else:\n",
    "                stagnation_counter += 1\n",
    "            \n",
    "            self.convergence_history.append(self.best_energy)\n",
    "            \n",
    "            if stagnation_counter >= self.stagnation_limit:\n",
    "                if verbose:\n",
    "                    print(f\"Converged at iteration {iteration}\")\n",
    "                break\n",
    "            \n",
    "            # Create new population via crossover/mutation\n",
    "            new_population = [improved_pop[0]]  # Elitism\n",
    "            \n",
    "            while len(new_population) < self.population_size:\n",
    "                p1 = min(random.sample(improved_pop, 2), key=lambda x: x[1])[0]\n",
    "                p2 = min(random.sample(improved_pop, 2), key=lambda x: x[1])[0]\n",
    "                \n",
    "                child = self.crossover(p1, p2)\n",
    "                mutation_rate = 0.05 + 0.15 * (stagnation_counter / self.stagnation_limit)\n",
    "                child = self.mutate(child, mutation_rate)\n",
    "                \n",
    "                child_energy = self._labs_energy(child)\n",
    "                new_population.append((child, child_energy))\n",
    "            \n",
    "            pop_with_energy = new_population\n",
    "        \n",
    "        return self.best_sequence, self.best_energy, {\n",
    "            'iterations': self.iteration_count,\n",
    "            'evaluations': self.eval_count,\n",
    "            'convergence_history': self.convergence_history\n",
    "        }\n",
    "\n",
    "print(\"Memetic Tabu Search loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4d153e-a57d-468e-bd5a-b396148d8af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline loaded! Ready to run.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Complete Pipeline\n",
    "import time\n",
    "\n",
    "class LABSHybridPipeline:\n",
    "    \"\"\"Full TDA filtering pipeline for quantum-enhanced LABS optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, N: int, dcqo_layers: int = 3, dcqo_samples: int = 2000,\n",
    "                 mts_population: int = 10, mts_iterations: int = 5000):\n",
    "        self.N = N\n",
    "        self.dcqo_samples = dcqo_samples\n",
    "        \n",
    "        self.dcqo = DCQOSampler(N=N, num_layers=dcqo_layers)\n",
    "        self.tda = TDABasinAnalyzer(persistence_threshold=0.15)\n",
    "        self.selector = DiversitySelector()\n",
    "        self.mts = MemeticTabuSearch(N=N, population_size=mts_population,\n",
    "                                     max_iterations=mts_iterations)\n",
    "        \n",
    "        self.results = {}\n",
    "        self.timing = {}\n",
    "    \n",
    "    def run(self, verbose: bool = True) -> Dict:\n",
    "        \"\"\"Execute the full pipeline\"\"\"\n",
    "        total_start = time.time()\n",
    "        \n",
    "        # ========== STAGE 0: DCQO Sampling ==========\n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"LABS Hybrid Pipeline - N={self.N}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            print(\"\\n[Stage 0] DCQO Quantum Sampling...\")\n",
    "        \n",
    "        stage_start = time.time()\n",
    "        dcqo_results = self.dcqo.sample(num_samples=self.dcqo_samples)\n",
    "        \n",
    "        # Deduplicate\n",
    "        seen = set()\n",
    "        unique_samples = []\n",
    "        for seq, energy in dcqo_results:\n",
    "            key = tuple(seq)\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                unique_samples.append((seq, energy))\n",
    "        \n",
    "        sequences = [s[0] for s in unique_samples]\n",
    "        energies = [s[1] for s in unique_samples]\n",
    "        \n",
    "        self.timing['dcqo'] = time.time() - stage_start\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Generated {len(sequences)} unique samples\")\n",
    "            print(f\"  Best DCQO energy: {min(energies)}\")\n",
    "            print(f\"  Time: {self.timing['dcqo']:.2f}s\")\n",
    "        \n",
    "        # ========== STAGE 1: TDA Basin Analysis ==========\n",
    "        if verbose:\n",
    "            print(\"\\n[Stage 1] TDA Basin Analysis...\")\n",
    "        \n",
    "        stage_start = time.time()\n",
    "        tda_results = self.tda.compute_persistence(sequences, energies)\n",
    "        cluster_labels = self.tda.assign_clusters(sequences, tda_results['distance_matrix'])\n",
    "        \n",
    "        self.timing['tda'] = time.time() - stage_start\n",
    "        \n",
    "        if verbose:\n",
    "            n_clusters = len(set(cluster_labels))\n",
    "            print(f\"  Identified {n_clusters} basins\")\n",
    "            print(f\"  Median persistence: {tda_results['basin_info'].get('median_persistence', 0):.2f}\")\n",
    "            print(f\"  Time: {self.timing['tda']:.2f}s\")\n",
    "        \n",
    "        # ========== STAGE 2: Diverse Seed Selection ==========\n",
    "        if verbose:\n",
    "            print(\"\\n[Stage 2] Diversity-Aware Selection...\")\n",
    "        \n",
    "        stage_start = time.time()\n",
    "        \n",
    "        selected_indices = self.selector.select_seeds(\n",
    "            sequences=sequences,\n",
    "            energies=energies,\n",
    "            cluster_labels=cluster_labels,\n",
    "            n_seeds=self.mts.population_size,\n",
    "            diversity_bonus=0.3\n",
    "        )\n",
    "        \n",
    "        selected_sequences = [sequences[i] for i in selected_indices]\n",
    "        selected_energies = [energies[i] for i in selected_indices]\n",
    "        selected_clusters = [cluster_labels[i] for i in selected_indices]\n",
    "        \n",
    "        self.timing['selection'] = time.time() - stage_start\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Selected {len(selected_sequences)} seeds\")\n",
    "            print(f\"  From {len(set(selected_clusters))} different clusters\")\n",
    "            print(f\"  Energy range: [{min(selected_energies)}, {max(selected_energies)}]\")\n",
    "            print(f\"  Time: {self.timing['selection']:.2f}s\")\n",
    "        \n",
    "        # ========== STAGE 3: MTS Optimization ==========\n",
    "        if verbose:\n",
    "            print(\"\\n[Stage 3] Memetic Tabu Search...\")\n",
    "        \n",
    "        stage_start = time.time()\n",
    "        \n",
    "        best_sequence, best_energy, mts_stats = self.mts.optimize(\n",
    "            initial_population=selected_sequences,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        self.timing['mts'] = time.time() - stage_start\n",
    "        self.timing['total'] = time.time() - total_start\n",
    "        \n",
    "        # ========== Results Summary ==========\n",
    "        best_merit = merit_factor(best_sequence)\n",
    "        \n",
    "        self.results = {\n",
    "            'N': self.N,\n",
    "            'best_sequence': best_sequence.tolist(),\n",
    "            'best_energy': int(best_energy),\n",
    "            'merit_factor': float(best_merit),\n",
    "            'dcqo_samples': len(sequences),\n",
    "            'dcqo_best_energy': int(min(energies)),\n",
    "            'n_basins': len(set(cluster_labels)),\n",
    "            'mts_iterations': mts_stats['iterations'],\n",
    "            'mts_evaluations': mts_stats['evaluations'],\n",
    "            'timing': self.timing\n",
    "        }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(\"RESULTS SUMMARY\")\n",
    "            print(f\"{'='*50}\")\n",
    "            print(f\"Best Energy: {best_energy}\")\n",
    "            print(f\"Merit Factor: {best_merit:.4f}\")\n",
    "            print(f\"MTS Iterations: {mts_stats['iterations']}\")\n",
    "            print(f\"Total Time: {self.timing['total']:.2f}s\")\n",
    "            print(f\"\\nTiming Breakdown:\")\n",
    "            for stage, t in self.timing.items():\n",
    "                if stage != 'total':\n",
    "                    pct = 100 * t / self.timing['total']\n",
    "                    print(f\"  {stage}: {t:.2f}s ({pct:.1f}%)\")\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "print(\"Pipeline loaded! Ready to run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ccf4b1-23c1-4009-9139-5fe90c143bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SMALL TEST RUN (N=12)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "LABS Hybrid Pipeline - N=12\n",
      "==================================================\n",
      "\n",
      "[Stage 0] DCQO Quantum Sampling...\n",
      "  Generated 434 unique samples\n",
      "  Best DCQO energy: 10\n",
      "  Time: 0.13s\n",
      "\n",
      "[Stage 1] TDA Basin Analysis...\n",
      "  Identified 157 basins\n",
      "  Median persistence: 1.07\n",
      "  Time: 0.44s\n",
      "\n",
      "[Stage 2] Diversity-Aware Selection...\n",
      "  Selected 8 seeds\n",
      "  From 8 different clusters\n",
      "  Energy range: [10, 22]\n",
      "  Time: 0.00s\n",
      "\n",
      "[Stage 3] Memetic Tabu Search...\n",
      "Converged at iteration 99\n",
      "\n",
      "==================================================\n",
      "RESULTS SUMMARY\n",
      "==================================================\n",
      "Best Energy: 10\n",
      "Merit Factor: 7.2000\n",
      "MTS Iterations: 99\n",
      "Total Time: 10.49s\n",
      "\n",
      "Timing Breakdown:\n",
      "  dcqo: 0.13s (1.3%)\n",
      "  tda: 0.44s (4.2%)\n",
      "  selection: 0.00s (0.0%)\n",
      "  mts: 9.91s (94.5%)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: RUN THE PIPELINE\n",
    "# Start with a small N for testing, then scale up\n",
    "\n",
    "# Small test (fast, ~30 seconds)\n",
    "print(\"=\"*60)\n",
    "print(\"SMALL TEST RUN (N=12)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline_small = LABSHybridPipeline(\n",
    "    N=12,\n",
    "    dcqo_layers=2,\n",
    "    dcqo_samples=500,\n",
    "    mts_population=8,\n",
    "    mts_iterations=500\n",
    ")\n",
    "\n",
    "results_small = pipeline_small.run(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb78e11-feec-4d96-9c12-d4bef70c0dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FULL SCALE RUN (N=20)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "LABS Hybrid Pipeline - N=20\n",
      "==================================================\n",
      "\n",
      "[Stage 0] DCQO Quantum Sampling...\n",
      "  Generated 1804 unique samples\n",
      "  Best DCQO energy: 58\n",
      "  Time: 176.53s\n",
      "\n",
      "[Stage 1] TDA Basin Analysis...\n",
      "  Identified 879 basins\n",
      "  Median persistence: 1.33\n",
      "  Time: 7.21s\n",
      "\n",
      "[Stage 2] Diversity-Aware Selection...\n",
      "  Selected 10 seeds\n",
      "  From 10 different clusters\n",
      "  Energy range: [58, 74]\n",
      "  Time: 0.01s\n",
      "\n",
      "[Stage 3] Memetic Tabu Search...\n",
      "Iter 0: New best E=34, F=5.882\n",
      "Iter 1: New best E=26, F=7.692\n",
      "Converged at iteration 101\n",
      "\n",
      "==================================================\n",
      "RESULTS SUMMARY\n",
      "==================================================\n",
      "Best Energy: 26\n",
      "Merit Factor: 7.6923\n",
      "MTS Iterations: 101\n",
      "Total Time: 235.22s\n",
      "\n",
      "Timing Breakdown:\n",
      "  dcqo: 176.53s (75.0%)\n",
      "  tda: 7.21s (3.1%)\n",
      "  selection: 0.01s (0.0%)\n",
      "  mts: 51.47s (21.9%)\n",
      "\n",
      "Results saved to labs_results_n20.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: FULL SCALE RUN\n",
    "# This will use more compute - adjust based on your credits\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FULL SCALE RUN (N=20)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline_full = LABSHybridPipeline(\n",
    "    N=20,\n",
    "    dcqo_layers=3,\n",
    "    dcqo_samples=2000,\n",
    "    mts_population=10,\n",
    "    mts_iterations=2000\n",
    ")\n",
    "\n",
    "results_full = pipeline_full.run(verbose=True)\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "with open('labs_results_n20.json', 'w') as f:\n",
    "    json.dump(results_full, f, indent=2)\n",
    "print(\"\\nResults saved to labs_results_n20.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47c654-10d5-4b8f-997a-282693f15c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: FULL SCALE RUN\n",
    "# This will use more compute - adjust based on your credits\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FULL SCALE RUN (N=48)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline_full = LABSHybridPipeline(\n",
    "    N=48,\n",
    "    dcqo_layers=3,\n",
    "    dcqo_samples=2000,\n",
    "    mts_population=10,\n",
    "    mts_iterations=2000\n",
    ")\n",
    "\n",
    "results_full = pipeline_full.run(verbose=True)\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "with open('labs_results_n20.json', 'w') as f:\n",
    "    json.dump(results_full, f, indent=2)\n",
    "print(\"\\nResults saved to labs_results_n20.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fad676c-a9e5-4bd7-9de7-e3aec4d323e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in a cell before your pipeline\n",
    "from unittest.mock import patch\n",
    "import qiskit_aer\n",
    "\n",
    "original_run = qiskit_aer.AerSimulator.run\n",
    "\n",
    "def debug_run(self, circuits, **kwargs):\n",
    "    print(f\"AerSimulator.run called with method={self._method}, circuits={type(circuits)}\")\n",
    "    if hasattr(circuits, '__len__'):\n",
    "        print(f\"  Number of circuits: {len(circuits)}\")\n",
    "    import traceback\n",
    "    traceback.print_stack(limit=10)\n",
    "    return original_run(self, circuits, **kwargs)\n",
    "\n",
    "qiskit_aer.AerSimulator.run = debug_run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07f554b5-f2c1-4393-8a15-cf540a38a7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FULL SCALE RUN (N=48)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "LABS Hybrid Pipeline - N=48\n",
      "==================================================\n",
      "\n",
      "[Stage 0] DCQO Quantum Sampling...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AerSimulator' object has no attribute '_method'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 16\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m      8\u001b[0m pipeline_full \u001b[38;5;241m=\u001b[39m LABSHybridPipeline(\n\u001b[1;32m      9\u001b[0m     N\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m48\u001b[39m,\n\u001b[1;32m     10\u001b[0m     dcqo_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     mts_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m results_full \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline_full\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 33\u001b[0m, in \u001b[0;36mLABSHybridPipeline.run\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[Stage 0] DCQO Quantum Sampling...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m stage_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 33\u001b[0m dcqo_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdcqo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdcqo_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Deduplicate\u001b[39;00m\n\u001b[1;32m     36\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 64\u001b[0m, in \u001b[0;36mDCQOSampler.sample\u001b[0;34m(self, num_samples)\u001b[0m\n\u001b[1;32m     61\u001b[0m qc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_circuit()\n\u001b[1;32m     63\u001b[0m simulator \u001b[38;5;241m=\u001b[39m AerSimulator()\n\u001b[0;32m---> 64\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43msimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m counts \u001b[38;5;241m=\u001b[39m job\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mget_counts()\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Convert to sequences with energies\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m, in \u001b[0;36mdebug_run\u001b[0;34m(self, circuits, **kwargs)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdebug_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, circuits, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAerSimulator.run called with method=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_method\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, circuits=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(circuits)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(circuits, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__len__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Number of circuits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(circuits)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AerSimulator' object has no attribute '_method'"
     ]
    }
   ],
   "source": [
    "# Cell 8: FULL SCALE RUN\n",
    "# This will use more compute - adjust based on your credits\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FULL SCALE RUN (N=48)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pipeline_full = LABSHybridPipeline(\n",
    "    N=48,\n",
    "    dcqo_layers=3,\n",
    "    dcqo_samples=2000,\n",
    "    mts_population=10,\n",
    "    mts_iterations=2000\n",
    ")\n",
    "\n",
    "results_full = pipeline_full.run(verbose=True)\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "with open('labs_results_n20.json', 'w') as f:\n",
    "    json.dump(results_full, f, indent=2)\n",
    "print(\"\\nResults saved to labs_results_n20.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [cuda-q-v0.13.0]",
   "language": "python",
   "name": "python3_ol6s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
